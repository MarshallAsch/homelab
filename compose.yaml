name: homelab

services:

######################################################
#     DATABASES
#     192.168.4.20-29
######################################################
  mariadb:
    image: linuxserver/mariadb
    networks:
      - internal
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/mariadb:/config
    restart: unless-stopped

  fills_db:
    image: linuxserver/mariadb
    networks:
      - internal
    environment:
      - PUID
      - PGID
      - TZ
      - MYSQL_DATABASE=${FILLS_DB}
      - MYSQL_USER=${FILLS_USER}
      - MYSQL_PASSWORD=${FILLS_PASSWORD}
    volumes:
      - ${CONFIG_VOLUMES}/fills/db:/config
    restart: unless-stopped

  gitea_db:
    image: docker.io/library/postgres:14
    restart: always
    networks:
      - gitea_internal
    environment:
      - POSTGRES_USER=gitea
      - POSTGRES_PASSWORD=${GITEA_DB_PASSWORD}
      - POSTGRES_DB=gitea
    volumes:
      - ${CONFIG_VOLUMES}/gitea/postgres:/var/lib/postgresql/data

  immich_db:
    image: ghcr.io/immich-app/postgres:14-vectorchord0.3.0-pgvectors0.2.0
    networks:
      - immich_internal
    environment:
      POSTGRES_PASSWORD: ${IMMICH_DB_PASSWORD}
      POSTGRES_USER: postgres
      POSTGRES_DB: immich
      POSTGRES_INITDB_ARGS: '--data-checksums'
      # Uncomment the DB_STORAGE_TYPE: 'HDD' var if your database isn't stored on SSDs
      # DB_STORAGE_TYPE: 'HDD'
    volumes:
      - ${CONFIG_VOLUMES}/immich/db:/var/lib/postgresql/data
    restart: unless-stopped

  firefly_db:
    image: linuxserver/mariadb
    restart: unless-stopped
    env_file: .firefly.db.env
    environment:
      - MYSQL_PASSWORD=${FIREFLY_DB_PASSWORD}
    networks:
      - firefly_iii
    volumes:
      - ${CONFIG_VOLUMES}/firefly/db:/var/lib/mysql

  postal_db:
    image: linuxserver/mariadb
    networks:
      - internal
    environment:
      - PUID
      - PGID
      - TZ
      - MYSQL_DATABASE=${POSTAL_DB}
      - MYSQL_USER=${POSTAL_USER}
      - MYSQL_PASSWORD=${POSTAL_DB_PASSWORD}
    volumes:
      - ${CONFIG_VOLUMES}/postal/db:/config
    restart: unless-stopped

  mongo_botomir:
    image: mongo:5.0
    profiles:
      - temp
    #mem_limit: 500m
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.23
    environment:
      - TZ
      - MONGO_INITDB_DATABASE=discordbot
    volumes:
      - ${CONFIG_VOLUMES}/mongo_botomir/db:/data/db
      - ${CONFIG_VOLUMES}/mongo_botomir/mongo_init.js:/docker-entrypoint-initdb.d/init.js
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo mongo_botomir:27017/test --quiet
      timeout: 5s
      retries: 3
      interval: 10s
      start_period: 2s
    restart: unless-stopped

  authelia_redis:
    image: redis:7.2-alpine
    networks:
      - authelia_internal
    mem_limit: 2g
    restart: unless-stopped
    environment:
      - TZ

  immich_redis:
    image: docker.io/valkey/valkey:8-bookworm
    networks:
      - immich_internal
    healthcheck:
      test: redis-cli ping || exit 1
    restart: unless-stopped

  grampsweb_redis:
    image: docker.io/library/redis:7.2.4-alpine
    networks:
      - gramps_internal
    restart: unless-stopped
    environment:
      - TZ

  unifi-db:
    image: mongo:7.0.11
    networks:
      unifi: {}
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/unifi/db:/data/db
      - ${CONFIG_VOLUMES}/unifi/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    ports:
      - 27017:27017
    restart: unless-stopped

  openldap:
    image: osixia/openldap:latest
    hostname: ldap.marshallasch.ca
    volumes:
      - ${CONFIG_VOLUMES}/ldap/db:/var/lib/ldap
      - ${CONFIG_VOLUMES}/ldap/conf:/etc/ldap/slapd.d
    networks:
      authelia_internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.25
    restart: unless-stopped
    environment:
      TZ: ${TZ}
      LDAP_ORGANISATION: "Marshall Asch Homelab"
      LDAP_DOMAIN: "marshallasch.ca"
      LDAP_BASE_DN: "dc=marshallasch,dc=ca"
      LDAP_OPENLDAP_UID: "${PUID}"
      LDAP_OPENLDAP_GID: "${PGID}"
      LDAP_ADMIN_PASSWORD: "${LDAP_ADMIN_PASSWORD}" # password for admin@domain.tld
      LDAP_CONFIG_PASSWORD: "${LDAP_CONFIG_PASSWORD}" # password for config (not sure what this does)
      LDAP_TLS_VERIFY_CLIENT: "try"
      LDAP_READONLY_USER: "false"
      LDAP_RFC2307BIS_SCHEMA: "true"
      LDAP_REMOVE_CONFIG_AFTER_SETUP: "false"

######################################################
#     PROXIES
#     192.168.4.30-39
######################################################
  letsencrypt:
    image: linuxserver/swag
    networks:
      plex_internal: {}
      gitea_internal: {}
      ingress: {}
      immich_internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.31
    cap_add:
      - NET_ADMIN
    environment:
      - PUID
      - PGID
      - TZ
      - URL=${DOMAIN}
      - SUBDOMAINS=ombi,files,ha,home,collabora,botomir,cars,tunarr,speedtest,images,gramps,homebox,firefly,mail,dive,code
      - VALIDATION=http
      - ONLY_SUBDOMAINS=true
      - SWAG_AUTORELOAD=true
      - EMAIL=${EMAIL}
      - DOCKER_MODS=linuxserver/mods:swag-maxmind|linuxserver/mods:swag-dashboard
      - MAXMINDDB_USER_ID
      - MAXMINDDB_LICENSE_KEY
    volumes:
      - ${CONFIG_VOLUMES}/letsencrypt/config:/config
    restart: unless-stopped

  ddclient:
    image: lscr.io/linuxserver/ddclient:latest
    networks:
      - egress
    environment:
      - PUID
      - PGID
      - TZ
      - CLOUDFLARE_DNS_TOKEN
    volumes:
      - ${CONFIG_VOLUMES}/ddclient:/config
    restart: unless-stopped

######################################################
#     NON WEB
#     192.168.4.40-49
######################################################

  diun:
    image: crazymax/diun:latest
    command: serve
    networks:
      - egress
    volumes:
      - ${CONFIG_VOLUMES}/diun:/data
      - "/var/run/docker.sock:/var/run/docker.sock"
    environment:
      - TZ
      - "DIUN_WATCH_SCHEDULE=0 18 * * 1,4"
      - DIUN_PROVIDERS_DOCKER=true
      - DIUN_NOTIF_DISCORD_WEBHOOKURL=${DISCORD_URL}
      - DIUN_NOTIF_DISCORD_TEMPLATEBODY=An update is available for the {{ if .Entry.Image.HubLink }}[**{{ .Entry.Image }}**]({{ .Entry.Image.HubLink }}){{ else }}**{{ .Entry.Image }}**{{ end }}  on {{ .Entry.Image.Domain }}.
      - DIUN_PROVIDERS_DOCKER_WATCHBYDEFAULT=true
    restart: always

  minecraft:
    image: itzg/minecraft-server:latest
    profiles:
      - temp
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.41
    ports:
      - 25565:25565
    volumes:
      - ${CONFIG_VOLUMES}/direwolf20_1_19b:/data
    environment:
      - TZ
      - MEMORY=8G
      - EULA=TRUE
      - ONLINE_MODE=TRUE
      - TYPE=FTBA
      - FTB_MODPACK_ID=101
      - FTB_MODPACK_VERSION_ID=2342
      - MOTD="Our amazing house minecraft server"
      # - OPS="cb983183-3e15-4d0d-b16e-74fe031a0937,20c39344-2548-4ddb-b3a6-3315ee664ee3"
    restart: always

######################################################
#     INTERNAL ACCESS
#     192.168.4.100
######################################################
  sonarr:
    image: linuxserver/sonarr
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/sonarr:/config
      - ${MASS_VOLUMES}/plex:/plex
    restart: unless-stopped

  radarr:
    image: linuxserver/radarr
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/radarr:/config
      - ${MASS_VOLUMES}/plex:/plex
    restart: unless-stopped

  tunarr:
    image: chrisbenincasa/tunarr:latest-vaapi
    networks:
      - plex_internal
      - egress
    environment:
      - TZ
      - TUNARR_SERVER_TRUST_PROXY=true
    volumes:
      - ${CONFIG_VOLUMES}/tunarr:/config/tunarr
    devices:
      - /dev/dri:/dev/dri

  lidarr:
    image: linuxserver/lidarr
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/lidarr:/config
      - ${MASS_VOLUMES}/plex:/plex
    restart: unless-stopped

  unpackerr:
    image: golift/unpackerr
    networks:
      - plex_internal
    user: ${PUID}:${PGID}
    environment:
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/unpackerr:/config
      - ${MASS_VOLUMES}/plex:/plex
    restart: unless-stopped

  bazarr:
    image: linuxserver/bazarr
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/bazarr:/config
      - ${MASS_VOLUMES}/plex:/plex
    restart: unless-stopped

  prowlarr:
    image: linuxserver/prowlarr
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/prowlarr:/config
    restart: unless-stopped

  unifi:
    image: linuxserver/unifi-network-application:latest
    mem_limit: 2g
    networks:
      unifi: {}
      authelia_internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.103
        aliases:
          - thanatos
    depends_on:
      - unifi-db
    environment:
      - PUID
      - PGID
      - MONGO_USER=unifi
      - MONGO_PASS=$UNIFI_DB_PASS
      - MONGO_HOST=unifi-db
      - MONGO_PORT=27017
      - MONGO_DBNAME=unifi
    volumes:
      - ${CONFIG_VOLUMES}/unifi/new:/config
    ports:
      - 3478:3478/udp
      - 10001:10001/udp
      - 8080:8080
      - 8081:8081
      - 8443:8443
      - 8843:8843
      - 8880:8880
      - 6789:6789
    restart: unless-stopped

  transmission:
    image: haugene/transmission-openvpn:latest
    networks:
      - plex_internal
      - egress
    cap_add:
      - net_admin
    environment:
      - PUID
      - PGID
      - TZ
      - OPENVPN_PROVIDER=NORDVPN
      - NORDVPN_COUNTRY=CA
      - NORDVPN_CATEGORY=legacy_p2p
      - NORDVPN_PROTOCOL=tcp
      - OPENVPN_USERNAME=${VPN_USER}
      - OPENVPN_PASSWORD=${VPN_PASSWORD}
      - "LOCAL_NETWORK=${SUBNET}.0/24,192.168.1.0/24"
      - "OPENVPN_OPTS=--inactive 3600 --ping 10 --ping-exit 60"
      - "TRANSMISSION_DOWNLOAD_QUEUE_ENABLED=30"
      - "TRANSMISSION_MAX_PEERS_GLOBAL=400"
      - "TRANSMISSION_SCRAPE_PAUSED_TORRENTS_ENABLED=false"
    volumes:
      - ${MASS_VOLUMES}/plex/downloads:/data
      - ${CONFIG_VOLUMES}/vpn2:/data/transmission-home
      - ${CONFIG_VOLUMES}/jackett/torrents:/data/watch
    restart: unless-stopped

  lubelogger:
    image: ghcr.io/hargata/lubelogger:latest
    user: "${PUID}:${PGID}"
    networks:
      - plex_internal
      - internal
    environment:
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/lubelogger/config:/App/config
      - ${CONFIG_VOLUMES}/lubelogger/data:/App/data
      - ${CONFIG_VOLUMES}/lubelogger/documents:/App/wwwroot/documents
      - ${CONFIG_VOLUMES}/lubelogger/images:/App/wwwroot/images
      - ${CONFIG_VOLUMES}/lubelogger/log:/App/log
      - ${CONFIG_VOLUMES}/lubelogger/keys:/root/.aspnet/DataProtection-Keys
    restart: unless-stopped

  paperless:
    image: linuxserver/paperless-ng
    profiles:
      - temp
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.108
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/paperless:/config
      - ${MASS_VOLUMES}/paperless:/data
    restart: unless-stopped

  radarr4k:
    image: linuxserver/radarr
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/radarr_4k:/config
      - ${MASS_VOLUMES}/plex:/plex
    restart: unless-stopped

  ldap-user-manager:
    image: wheelybird/ldap-user-manager:latest
    networks:
      - authelia_internal
      - plex_internal
    restart: unless-stopped
    depends_on:
      - openldap
    environment:
      TZ: ${TZ}
      SERVER_HOSTNAME: "home.marshallasch.ca" # url for webui
      SERVER_PATH: "/ldap"
      ORGANISATION_NAME: "Marshall Asch Homelab" # Org name
      LDAP_URI: "ldaps://openldap"
      LDAP_IGNORE_CERT_ERRORS: "true"
      LDAP_BASE_DN: "dc=marshallasch,dc=ca" # edit domain tld same as above
      LDAP_ADMINS_GROUP: "admins" # admin group
      LDAP_ADMIN_BIND_DN: "cn=admin,dc=marshallasch,dc=ca" # edit domain tld
      LDAP_ADMIN_BIND_PWD: "${LDAP_ADMIN_PASSWORD}" # admin password set above
      LDAP_USES_NIS_SCHEMA: "false"
      LDAP_REQUIRE_STARTTLS: "false"
      EMAIL_DOMAIN: "marshallasch.ca" # email @this.part.here
      NO_HTTPS: "true"
      SMTP_HOSTNAME: ${SMTP_HOST}
      SMTP_HOST_PORT: ${SMTP_PORT}
      SMTP_USERNAME: ${SMTP_USER}
      SMTP_PASSWORD: ${SMTP_PASS}
      SMTP_USE_TLS: TRUE
      EMAIL_FROM_ADDRESS: "no-reply@marshallasch.ca" # your email address
      REMOTE_HTTP_HEADERS_LOGIN: "TRUE"
      USERNAME_FORMAT: "{first_name}{last_name}"
      ENFORCE_SAFE_SYSTEM_NAMES: "FALSE"
      LDAP_ACCOUNT_ADDITIONAL_ATTRIBUTES: "cn:Display Name,quota_files:Storage quota for Nextcloud,quota_images:Storage quota for immich"

  speedtest:
    image: lscr.io/linuxserver/speedtest-tracker:latest
    restart: unless-stopped
    networks:
      - ingress
      - egress
    environment:
      - PUID
      - PGID
      - APP_TIMEZONE=${TZ}
      - APP_KEY=${SPEEDTEST_KEY}
      - SPEEDTEST_SCHEDULE='6 */6 * * *'
      - PRUNE_RESULTS_OLDER_THAN=60
      - DB_CONNECTION=sqlite
      - APP_URL=https://speedtest.marshallasch.ca
      - ASSET_URL=https://speedtest.marshallasch.ca
    volumes:
      - ${CONFIG_VOLUMES}/speedtest:/config

  immich_server:
    image: ghcr.io/immich-app/immich-server:release
    networks:
      - immich_internal
      - egress
    # extends:
    #   file: hwaccel.transcoding.yml
    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    volumes:
      - ${MASS_VOLUMES}/images/:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
      - ${MASS_VOLUMES}/nextcloud/marshallasch/files/Pictures:/external/marshall:ro
      - ${MASS_VOLUMES}/nextcloud/murrayasch/files:/external/murray:ro
    environment:
      - TZ
      - DB_HOSTNAME=immich_db
      - REDIS_HOSTNAME=immich_redis
      - DB_USERNAME=postgres
      - DB_DATABASE_NAME=immich
      - DB_PASSWORD=${IMMICH_DB_PASSWORD}
    depends_on:
      - immich_redis
      - immich_db
    restart: unless-stopped
    healthcheck:
      disable: false

  immich_ml:
    # For hardware acceleration, add one of -[armnn, cuda, rocm, openvino, rknn] to the image tag.
    image: ghcr.io/immich-app/immich-machine-learning:release
    networks:
      - immich_internal
      - egress
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, rocm, openvino, openvino-wsl, rknn] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    volumes:
      - model-cache:/cache
    environment:
      - TZ
      - DB_HOSTNAME=immich_db
      - REDIS_HOSTNAME=immich_redis
      - DB_USERNAME=postgres
      - DB_DATABASE_NAME=immich
      - DB_PASSWORD=${IMMICH_DB_PASSWORD}
    restart: unless-stopped
    healthcheck:
      disable: false

  firefly:
    image: fireflyiii/core:latest
    restart: unless-stopped
    volumes:
      - ${CONFIG_VOLUMES}/firefly/upload:/var/www/html/storage/upload
    env_file: .firefly.env
    environment:
      - DB_PASSWORD=${FIREFLY_DB_PASSWORD}
    networks:
      - firefly_iii
      - ingress
      - lab_net
    ports:
      - 80:8080
    depends_on:
      - firefly_db

  firefly_cron:
    #
    # To make this work, set STATIC_CRON_TOKEN in your .env file or as an environment variable and replace PLEASE_REPLACE_WITH_32_CHAR_CODE below
    # The STATIC_CRON_TOKEN must be *exactly* 32 characters long
    #
    image: alpine
    restart: unless-stopped
    env_file: .firefly.env
    environment:
      - DB_PASSWORD=${FIREFLY_DB_PASSWORD}
    command: sh -c "
      apk add tzdata
      && ln -s /usr/share/zoneinfo/${TZ} /etc/localtime
      | echo \"0 3 * * * wget -qO- http://app:8080/api/v1/cron/PLEASE_REPLACE_WITH_32_CHAR_CODE;echo\"
      | crontab -
      && crond -f -L /dev/stdout"
    networks:
      - firefly_iii

  firefly_import:
    image: fireflyiii/data-importer:latest
    networks:
      - firefly_iii
      - lab_net
    env_file: .importer.env

######################################################
#     EXTERNAL ACCESS
#     192.168.4.200
######################################################
  nextcloud:
    image: linuxserver/nextcloud
    depends_on:
      - mariadb
    networks:
      - internal
      - ingress
      - egress
      - authelia_internal
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/nextcloud/config:/config
      - ${MASS_VOLUMES}/nextcloud:/data
    restart: unless-stopped

  plex:
    image: plexinc/pms-docker:plexpass
    networks:
      plex_internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.201
    environment:
      - TZ="America/Toronto"
      - PLEX_CLAIM=${PLEX_CLAIM}
      - PLEX_UID=${PUID}
      - PLEX_GID=${PGID}
      - CHANGE_CONFIG_DIR_OWNERSHIP=false
      - PLEX_UPDATE_CHANNEL=4
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ${CONFIG_VOLUMES}/plex/config:/config
      - "${MASS_VOLUMES}/plex/extra_data:/config/Library/Application Support/Plex Media Server/Media"
      - ${MASS_VOLUMES}/plex:/data
      - /dev/shm:/transcode
      - /mnt/hdd:/downloads
    restart: unless-stopped

  postal:
    image: ghcr.io/postalserver/postal:3.3.3
    networks:
      internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.202
    command: postal web-server
    depends_on:
      - postal_db
    environment:
      - MAIN_DB_PASSWORD=${POSTAL_DB_PASSWORD}
      - MESSAGE_DB_PASSWORD=${POSTAL_DB_PASSWORD}
    volumes:
      - ${CONFIG_VOLUMES}/postal/app:/config
    restart: unless-stopped

  postal_worker:
    image: ghcr.io/postalserver/postal:3.3.4
    networks:
      internal: {}
      egress: {}
    command: postal worker
    depends_on:
      - postal_db
    environment:
      - MAIN_DB_PASSWORD=${POSTAL_DB_PASSWORD}
      - MESSAGE_DB_PASSWORD=${POSTAL_DB_PASSWORD}
    volumes:
      - ${CONFIG_VOLUMES}/postal/app:/config
    restart: unless-stopped

  postal_smtp:
    image: ghcr.io/postalserver/postal:3.3.4
    networks:
      internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.203
    command: postal smtp-server
    depends_on:
      - postal_db
    environment:
      - MAIN_DB_PASSWORD=${POSTAL_DB_PASSWORD}
      - MESSAGE_DB_PASSWORD=${POSTAL_DB_PASSWORD}
    volumes:
      - ${CONFIG_VOLUMES}/postal/app:/config
    restart: unless-stopped

  ombi:
    image: linuxserver/ombi
    networks:
      - plex_internal
      - egress
    environment:
      - PUID
      - PGID
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/ombi:/config
    restart: unless-stopped

  tautulli:
    image: tautulli/tautulli
    networks:
      - plex_internal
      - egress
    environment:
      - TZ
      - PGID
      - PUID
    volumes:
      - ${CONFIG_VOLUMES}/tautulli:/config
      - ${CONFIG_VOLUMES}/plex/config/Library/Application Support/Plex Media Server/Logs:/plex_logs:ro
    restart: unless-stopped

  calibre:
    image: linuxserver/calibre-web
    networks:
      - authelia_internal
      - ingress
      - egress
    environment:
     - PUID
     - PGID
     - TZ
     - DOCKER_MODS=linuxserver/mods:universal-calibre
    volumes:
     - ${CONFIG_VOLUMES}/calibre-web/config:/config
     - ${CONFIG_VOLUMES}/calibre/config/Calibre Library:/books:ro
    restart: unless-stopped

  collabora:
    image: collabora/code
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.207
    cap_add:
      - MKNOD
    environment:
      - "dictionaries=en_GB en_US"
      - domain=files.${DOMAIN}
      - username=admin
      - password=${COLLABORA_PASSWORD}
    restart: unless-stopped

  gitea:
    image: docker.gitea.com/gitea:1.25.3-rootless
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    networks:
      gitea_internal: {}
      authelia_internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.208
    depends_on:
      - gitea_db
    environment:
      - GITEA__database__DB_TYPE=postgres
      - GITEA__database__HOST=gitea_db:5432
      - GITEA__database__NAME=gitea
      - GITEA__database__USER=gitea
      - GITEA__database__PASSWD=${GITEA_DB_PASSWORD}
      - GITEA__server__SSH_PORT=22
      - GITEA__server__SSH_LISTEN_PORT=2222
    volumes:
      - ${CONFIG_VOLUMES}/gitea/data:/var/lib/gitea
      - ${CONFIG_VOLUMES}/gitea/config:/etc/gitea
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro

  peanut:
    image: brandawg93/peanut:latest
    restart: unless-stopped
    networks:
      internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.160
    volumes:
      - ${CONFIG_VOLUMES}/peanut:/config
    environment:
      - WEB_PORT=8080
      - BASE_PATH=/peanut

  homepage:
    image: ghcr.io/gethomepage/homepage:v1.5
    networks:
      - internal
      - plex_internal
      - egress
    volumes:
      - ${CONFIG_VOLUMES}/homepage:/app/config # Make sure your local config directory exists
      - ${MASS_VOLUMES}/hdd:/scratch:ro
      # - /var/run/docker.sock:/var/run/docker.sock # (optional) For docker integrations
    environment:
      - HOMEPAGE_ALLOWED_HOSTS=home.marshallasch.ca
      - LOG_LEVEL=debug
      - PUID
      - PGID
      - TZ

  botomir:
    image: marshallasch/botomir
    networks:
      - ingress
      - egress
    environment:
      - TZ
    env_file:
      - ./botomir.env
    restart: unless-stopped

  wrapped:
    image: aunefyren/wrapperr:latest
    networks:
      - plex_internal
      - ingress
      - egress
    environment:
      - TZ
    volumes:
      - ${CONFIG_VOLUMES}/wrapperr/:/app/config
    restart: unless-stopped

  plexripper:
    image: plexripper/plexripper:0.31.1
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.155
    environment:
     - PUID
     - PGID
     - TZ
    volumes:
    - ${MASS_VOLUMES}/plex:/plex
    - ${CONFIG_VOLUMES}/plexripper:/Config
    ports:
      - 7000:7000

######################################################
#       done service list
#     temporary testing services
#       192.168.4.150-199
######################################################
  # this is the pimary DNS server
  # need to figure out a better secondary for the backup
  pihole:
    image: pihole/pihole:latest
    networks:
      internal: {}
      lab_net:
        ipv4_address: ${SUBNET}.150
        aliases:
           - dns1
    dns:
      - 127.0.0.1
      - 1.1.1.1
      - 1.0.0.1
    cap_add:
      - CAP_NET_BIND_SERVICE
    ports:
      - "53:53/tcp"
      - "53:53/udp"
      - "67:67/udp"
      - "80:80/tcp"
      - "443:443/tcp"
    environment:
      - TZ
      - WEBPASSWORD=${DNS_WEB_PASSWORD}
      - ADMIN_EMAIL=${EMAIL}
      - DNSMASQ_USER=root
    volumes:
      - ${CONFIG_VOLUMES}/pihole/config:/etc/pihole
      - ${CONFIG_VOLUMES}/pihole/dnsmasq:/etc/dnsmasq.d
    restart: unless-stopped

  homeassistant:
    image: linuxserver/homeassistant
    networks:
      ingress: {}
      lab_net:
        ipv4_address: ${SUBNET}.151
    environment:
     - PUID
     - PGID
     - TZ
    volumes:
     - ${CONFIG_VOLUMES}/homeassistant:/config
    ports:
     - 8123:80
    restart: unless-stopped

  authelia:
    image: authelia/authelia:4.39
    networks:
      - plex_internal
      - egress
      - authelia_internal
    environment:
      TZ: "${TZ}"
      AUTHELIA_NOTIFIER_SMTP_USERNAME: ${SMTP_USER}
      AUTHELIA_NOTIFIER_SMTP_ADDRESS: "smtp://${SMTP_HOST}:${SMTP_PORT}"
      AUTHELIA_AUTHENTICATION_BACKEND_LDAP_PASSWORD_FILE: '/run/secrets/ldap_admin_password'
      AUTHELIA_NOTIFIER_SMTP_PASSWORD_FILE: '/run/secrets/smtp_password'
      AUTHELIA_IDENTITY_PROVIDERS_OIDC_HMAC_SECRET_FILE: '/run/secrets/oidc_hmac'
      X_AUTHELIA_CONFIG_FILTERS: template
    volumes:
      - ${CONFIG_VOLUMES}/authelia:/config
    secrets:
      - ldap_admin_password
      - smtp_password
      - oidc_hmac
    restart: unless-stopped

  printer:
    image: thyrlian/air-pdf-printer
    hostname: printer
    profiles:
      - temp
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.153
    volumes:
      - ${CONFIG_VOLUMES}/printer/pdf:/root/PDF
      - ${CONFIG_VOLUMES}/printer/cups:/var/spool/cups-pdf

  handbrake:
    image: jlesage/handbrake
    networks:
      lab_net:
        ipv4_address: ${SUBNET}.154
    environment:
     - PUID
     - PGID
     - TZ
     - USER_ID=$PUID
     - GROUP_ID=$PGID
    volumes:
     - ${CONFIG_VOLUMES}/handbrake/config:/config
     - ${CONFIG_VOLUMES}/handbrake/watch:/watch
     - ${CONFIG_VOLUMES}/handbrake/storage:/storage
     - ${CONFIG_VOLUMES}/handbrake/output:/output
    ports:
     - 5800:5800
    restart: unless-stopped

  grampsweb: &grampsweb
    image: ghcr.io/gramps-project/grampsweb:latest
    restart: unless-stopped
    networks:
      - gramps_internal
      - ingress
    environment:
      GRAMPSWEB_TREE: "Gramps Web"  # will create a new tree if not exists
      GRAMPSWEB_CELERY_CONFIG__broker_url: "redis://grampsweb_redis:6379/0"
      GRAMPSWEB_CELERY_CONFIG__result_backend: "redis://grampsweb_redis:6379/0"
      GRAMPSWEB_RATELIMIT_STORAGE_URI: redis://grampsweb_redis:6379/1
      BASE_URL: "https://gramps.marshallasch.ca/"
      EMAIL_HOST: ${SMTP_HOST}
      EMAIL_PORT: ${SMTP_PORT}
      EMAIL_HOST_USER: ${SMTP_USER}
      EMAIL_HOST_PASSWORD: ${SMTP_PASS}
      DEFAULT_FROM_EMAIL: "gramps@marshallasch.ca"
    depends_on:
      - grampsweb_redis
    volumes:
      - ${CONFIG_VOLUMES}/gramps/users:/app/users  # persist user database
      - ${CONFIG_VOLUMES}/gramps/index:/app/indexdir  # persist search index
      - ${CONFIG_VOLUMES}/gramps/thumb_cache:/app/thumbnail_cache  # persist thumbnails
      - ${CONFIG_VOLUMES}/gramps/cache:/app/cache  # persist export and report caches
      - ${CONFIG_VOLUMES}/gramps/secret:/app/secret  # persist flask secret
      - ${CONFIG_VOLUMES}/gramps/db:/root/.gramps/grampsdb  # persist Gramps database
      - ${CONFIG_VOLUMES}/gramps/media:/app/media  # persist media files

  grampsweb_celery:
    <<: *grampsweb  # YAML merge key copying the entire grampsweb service config
    networks:
      - gramps_internal
    depends_on:
      - grampsweb_redis
    command: celery -A gramps_webapi.celery worker --loglevel=INFO --concurrency=2

  homebox:
    image: ghcr.io/sysadminsmedia/homebox:latest-rootless
    restart: unless-stopped
    networks:
      - ingress
    user: ${PUID}:${PGID}
    environment:
    - TZ
    - HBOX_LOG_LEVEL=info
    - HBOX_LOG_FORMAT=text
    - HBOX_WEB_MAX_FILE_UPLOAD=10
    - HBOX_OPTIONS_ALLOW_ANALYTICS=false
    - HBOX_MAILER_HOST="${SMTP_HOST}"
    - HBOX_MAILER_PORT=${SMTP_PORT}
    - HBOX_MAILER_USERNAME="${SMTP_USER}"
    - HBOX_MAILER_PASSWORD="${SMTP_PASS}"
    - HBOX_MAILER_FROM=homebox@marshallasch.ca
    volumes:
      - ${CONFIG_VOLUMES}/homebox:/data

  fill-station:
    image: marshallasch/fill-station:main
    restart: unless-stopped
    networks:
      - ingress
      - internal
    environment:
      - DATABASE__HOST=fills_db
      - DATABASE__DATABASE=${FILLS_DB}
      - DATABASE__USERNAME=${FILLS_USER}
      - DATABASE__PASSWORD=${FILLS_PASSWORD}
    volumes:
      - ${CONFIG_VOLUMES}/fills/app:/config

secrets:
  ldap_admin_password:
    environment: "LDAP_ADMIN_PASSWORD"
  smtp_password:
    environment: "SMTP_PASS"
  oidc_hmac:
    environment: "AUTHELIA_OIDC_HMAC"

volumes:
  model-cache:
######################################################
#       NETWORK SETUP
######################################################
networks:
  internal:
    internal: true
  immich_internal:
    internal: true
  gramps_internal:
    internal: true
  gitea_internal:
    internal: true
  firefly_iii:
    internal: true
  plex_internal:
    internal: true
  authelia_internal:
    internal: true
  ingress:
    internal: true
  unifi:
    internal: true
  egress: {}
  lab_net:
    driver: macvlan
#    enable_ipv6: true
    driver_opts:
      parent: eno1
    ipam:
      driver: default
      config:
        - subnet: "${SUBNET}.0/24"
